# Quick Start Testing Guide - LLamaSharp Bot Name Synthesizer

## üöÄ 5-Minute Local Test

### Step 1: Build the Project
```bash
cd D:\Source\mostlylucid.stylobot

# Build core library (should take ~2 seconds)
dotnet build Mostlylucid.BotDetection/Mostlylucid.BotDetection.csproj -c Release
```

**Expected Output**:
```
Build succeeded in 00:00:02.04
```

‚úÖ If you see "Build succeeded", proceed to Step 2.

---

### Step 2: Run Integration Test
```bash
# Run the quick integration test
dotnet script test-llm-integration.csx
```

**Expected Output**:
```
üîç Testing LLamaSharp Bot Name Synthesizer...

‚úì Synthesizer registered: LlamaSharpBotNameSynthesizer
‚úì Is Ready: False
‚ÑπÔ∏è  Note: First initialization downloads GGUF (~1.5GB)
   This happens on first inference, not startup.

Test signals prepared:
  detection.useragent.source: Mozilla/5.0 (compatible; Googlebot/2.1)
  detection.ip.type: datacenter
  detection.behavioral.rate_limit_violations: 5
  detection.correlation.primary_behavior: aggressive_crawl

‚è≥ Attempting bot name synthesis (will timeout gracefully if model unavailable)...
‚ö†Ô∏è  Synthesis returned null (model not available or timeout)
   This is expected if GGUF hasn't been downloaded yet.

‚úì Integration test completed!
```

‚úÖ **What this means**: The synthesizer is wired up correctly. On first run, GGUF downloads (takes 2-3 min).

---

### Step 3: Test with Local Demo App

If you have the demo application:

```bash
# Run with custom model cache
$env:STYLOBOT_MODEL_CACHE = "$PWD\models"
dotnet run --project Mostlylucid.BotDetection.Demo
```

Navigate to: `https://localhost:5001/SignatureDemo`

**What to expect**:
- Page loads normally (doesn't need LLM)
- Background: Model downloads on first detection
- Subsequent detections show bot names in console

---

## üîç Verification Checklist

### ‚úÖ Code Compilation
```bash
# Should pass in < 5 seconds
dotnet build Mostlylucid.BotDetection -q
```

### ‚úÖ No Runtime Errors
```bash
# Create minimal test
cat > test.cs << 'EOF'
using Mostlylucid.BotDetection.Services;
using Mostlylucid.BotDetection.Models;

var synthesizer = new LlamaSharpBotNameSynthesizer(
    logger: null!,  // ILogger - can be null for this test
    options: null!  // IOptions - will fail gracefully
);

Console.WriteLine($"Synthesizer type: {synthesizer.GetType().Name}");
Console.WriteLine($"Is ready: {synthesizer.IsReady}");
EOF

# Compile test
dotnet build test.cs --project Mostlylucid.BotDetection -q
```

### ‚úÖ Configuration Valid
```bash
# Check if appsettings.json is valid
dotnet run --project Mostlylucid.BotDetection.Demo -- --validate-config
```

---

## üìä What Gets Downloaded

On first inference, the system downloads:

```
Model: Qwen 2.5 0.5B Instruct (GGUF - Q4 quantized)
File:  qwen2.5-0.5b-instruct-q4_k_m.gguf
Size:  ~340 MB
Time:  2-5 minutes (depending on connection)
Cache: ~/.cache/stylobot-models/ (or /models in Docker)
```

**This happens once and is cached forever.**

---

## üêõ Troubleshooting

### "Build Failed"
```
Error: Building target "CoreCompile" completely
```
**Fix**:
```bash
dotnet clean Mostlylucid.BotDetection
dotnet build Mostlylucid.BotDetection -c Release
```

### "Can't Find Module"
```
Error: Model file not found: Qwen/Qwen2.5-0.5B-Instruct-GGUF/...
```
**Fix**:
Set cache directory and run:
```bash
$env:STYLOBOT_MODEL_CACHE = "C:\Models"
mkdir C:\Models  # Create it first
```

### "Synthesis Timeout"
```
‚è±Ô∏è  Synthesis timed out (expected on first run during download)
```
**Fix**:
This is normal. First run downloads the model. Wait 2-5 minutes and try again.

### "Out of Memory"
```
OutOfMemoryException: Exception of type 'System.OutOfMemoryException' was thrown.
```
**Fix**:
Qwen 0.5B needs ~350MB. Check available RAM:
```bash
# Windows
Get-WmiObject Win32_OperatingSystem | Select-Object @{Name="AvailableMemory_GB"; Expression={$_.FreePhysicalMemory/1MB}}

# Linux
free -h

# Mac
vm_stat
```

---

## üéØ Expected Timeline

| Phase | Time | What's Happening |
|-------|------|-----------------|
| **Build** | 2s | Compiling C# code |
| **First Test** | 2-3 min | Downloading GGUF from HF |
| **Synthesis** | 80-150ms | Running Qwen on detection |
| **Cache** | <1ms | Reusing cached model |

---

## ‚úÖ Success Indicators

### Minimal Success (Just Compiles)
- ‚úÖ `dotnet build` succeeds
- ‚úÖ No CS errors
- ‚úÖ Services register in DI

### Partial Success (Downloads Start)
- ‚úÖ Synthesizer initializes
- ‚úÖ GGUF download begins
- ‚úÖ No crashes during download

### Full Success (All Working)
- ‚úÖ Model loads (~3 seconds)
- ‚úÖ Inference runs in <200ms
- ‚úÖ Bot names generated
- ‚úÖ Names cached for future requests

---

## üìù Logging Output

When everything works, you'll see:

```
[INF] Initializing LlamaSharp model (CPU-only): Qwen/Qwen2.5-0.5B-Instruct-GGUF/qwen2.5-0.5b-instruct-q4_k_m.gguf
[INF] Downloading model from Hugging Face: Qwen/Qwen2.5-0.5B-Instruct-GGUF/qwen2.5-0.5b-instruct-q4_k_m.gguf
[INF] Downloading from https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct-GGUF/resolve/main/qwen2.5-0.5b-instruct-q4_k_m.gguf
[INF] Model downloaded to ~/.cache/stylobot-models/Qwen_Qwen2.5-0.5B-Instruct-GGUF_qwen2.5-0.5b-instruct-q4_k_m.gguf
[INF] LlamaSharp model initialized successfully. CPU cores: 8, IsReady: True
[INF] Signature abc123def456 reached threshold (50 requests), queuing description synthesis
[INF] Generated description for signature abc123def456: 'GoogleBot'
```

---

## üöÄ Ready to Deploy?

Once you pass all checks above:

```bash
# 1. Build release
dotnet build -c Release

# 2. Create Docker image
docker build -t stylobot:latest .

# 3. Run with volume
docker run -v llm-models:/models stylobot:latest

# 4. Test endpoint
curl http://localhost:5000/health
```

---

## üí° Pro Tips

### Disable LLM Temporarily (Testing)
```json
{
  "BotDetection": {
    "AiDetection": {
      "LlamaSharp": {
        "Enabled": false
      }
    }
  }
}
```

### Use Different Model
```json
{
  "BotDetection": {
    "AiDetection": {
      "LlamaSharp": {
        "ModelPath": "TheBloke/Mistral-7B-Instruct-v0.1-GGUF/mistral-7b-instruct-v0.1.Q4_K_M.gguf"
      }
    }
  }
}
```

### Increase Threshold (Fewer Syntheses)
```json
{
  "BotDetection": {
    "SignatureDescriptionThreshold": 100  // Require 100 requests
  }
}
```

---

## ‚úÖ You're Done!

Once the test passes, the implementation is **production-ready**.

**Next**: Follow `UI_INTEGRATION_GUIDE.md` to wire up the dashboard.

---

**Questions?** Check `CODE_REVIEW.md` or `LLAMA_IMPLEMENTATION_COMPLETE.md` for details.

Good luck! üöÄ

