Here’s a concrete functional spec you can actually build tests from, with soak-focused expectations and k6 threshold
examples baked in.

---

## 1. Purpose

Validate that **Mostlylucid.BotDetection**:

1. Correctly classifies and blocks abusive / bot traffic.
2. Does **not** over-block legitimate traffic under load.
3. Maintains stable behaviour over **soak runs** (learning, reputation, decay, policies etc. don’t drift into madness
   under real-world patterns).

We test both:

* **Functional behaviour** (per scenario: who gets blocked / challenged / allowed)
* **Non-functional behaviour** (latency overhead, stability, memory, leakiness over time)

---

## 2. System Under Test (SUT)

* ASP.NET Core app with **Mostlylucid.BotDetection** middleware enabled.
* Configured with:

    * Full blackboard pipeline (UA, header, IP, behavioural, inconsistency, optional AI).
    * Learning + reputation enabled.
    * Path-based policies (e.g. `/`, `/static/**` relaxed, `/login`, `/checkout`, `/api/**` strict).
* Two relevant modes:

    1. **Test mode**: detection fully active, but **no real blocking**; block/allow returned via headers (e.g.
       `X-BotDetection-Risk`, `X-BotDetection-Verdict`).
    2. **Enforcement mode**: real blocking (403 or similar).

You’ll use **test mode** for most soak / tuning runs, and **enforcement mode** for final “does it actually block”
checks.

---

## 3. Test Environment

* Dedicated test app instance so learning/reputation state is isolated.
* Stable backing services (SQL / Redis / whatever you use for reputation and metrics).
* OTEL export enabled (Prometheus / Jaeger / whatever you like) for post-hoc sanity checks.

---

## 4. Traffic Profiles (k6 Scenarios)

Each **scenario** in k6 simulates one population type. Internally you tag requests with `scenario` so you can compute
per-scenario block rates.

### 4.1 Legitimate Humans

**Profile**

* Modern browser UAs (Chrome/Firefox/Safari, desktop & mobile).
* Realistic headers: `Accept`, `Accept-Language`, `sec-*`, `Referer` sometimes, cookies across requests.
* Pace: 1–5 seconds between page views.
* Paths: `/`, `/articles/{id}`, `/static/*`, `/login`, some `/api/*` calls.

**Expected Behaviour**

* Risk band: mostly **Low**.
* Very rare blocks (<0.5%).
* Latency overhead from detection < ~10–20ms p95 (rough ballpark).

**Acceptance Criteria**

* False-positive block rate:

    * `blocked_humans_rate <= 0.005` (≤0.5%).

### 4.2 Allowed “Good” Bots (Search & Monitors)

**Profile**

* UAs: Googlebot, Bingbot, DuckDuckBot, etc.
* Polite crawl rate (≤1 req/sec per bot).
* Clean headers; correct `User-Agent`, often `Accept: */*`.

**Expected Behaviour**

* Classified as **bot** but treated as **Allowed / Soft-throttled** according to policy.
* Absolut minimum **hard blocks** (unless misconfigured policy).

**Acceptance Criteria**

* Hard block rate for good bots:

    * `blocked_goodbots_rate <= 0.01` (≤1% hard blocks).
* Risk band tends High, but mapped to “Allow” or “Throttle” action.

### 4.3 Obvious Trash Bots / Scanners

**Profile**

* UAs: `curl/7.*`, `python-requests/*`, random “Java/1.8.0” etc.
* Headers: bare minimum, missing Accept-Language, sec-*.
* High request rate: 50–200 req/sec, lots of 404-ish paths (`/wp-admin`, `/.env`, `/admin`, `/phpmyadmin`).

**Expected Behaviour**

* Very quickly classified as **High risk**.
* Hard blocked after a short warm-up (reputation kicks in quickly).

**Acceptance Criteria**

* Within **30s** of scenario start:

    * `blocked_trashbots_rate >= 0.95` (≥95% responses blocked).
* After **2 m**:

    * `blocked_trashbots_rate >= 0.99` (≥99%).

### 4.4 Stealth Scrapers

**Profile**

* UA looks like Chrome/Firefox.
* Some missing / weird headers:

    * Missing `Accept-Language` and sec-* or generic `Accept: */*`.
* Pace: perfectly regular 100–200ms intervals (inhumanly consistent).
* Hit many distinct pages in quick succession (`/articles/1..500`).

**Expected Behaviour**

* Initially tolerated / Medium risk.
* Behavioural + inconsistency detectors gradually push risk up.
* IP/fingerprint reputation increases.
* Eventually hit **Throttle / Challenge / Block** depending on policy for that path.

**Acceptance Criteria**

* During a 15–30 min soak:

    * Stealth scraper hard block rate should reach **≥70–80%** on protected paths (e.g. `/articles/**`).
    * On public static paths (if configured relaxed), likely fewer blocks – depends on your policy.

### 4.5 Path-Escalated / High-Value Endpoints

**Profile**

* Requests to `/login`, `/checkout`, `/api/private/**`, `/admin/**`.
* Mix of legitimate and malicious patterns.

**Expected Behaviour**

* Detection policy escalates:

    * Lower thresholds for “Challenge / Block”.
    * AI path maybe enabled even when not for general traffic.
* Attack-like patterns on these paths are blocked more aggressively.

**Acceptance Criteria**

* For “trash” + “stealth” bots targeting these endpoints:

    * Hard block rate ≥99% after warm-up.
* For legitimate users hitting `/login`:

    * Block rate <1% (ideally much lower).

---

## 5. Metrics & Instrumentation

### 5.1 What to Measure (Functionally)

Per scenario:

* **Total requests**.
* **Blocked requests** (e.g. HTTP 4xx/429/403 with `X-BotDetection-Action=Block` or similar).
* Calculated:

    * `blocked_rate = blocked / total`.

Optionally:

* **Risk band distribution** using headers:

    * `X-BotDetection-RiskBand: Low|Elevated|Medium|High`
    * So you can verify “humans mostly Low, trash mostly High”.

### 5.2 k6 Custom Metrics

In `k6`, define **Rates** per scenario:

```js
import { Rate } from 'k6/metrics';

export const blocked_humans = new Rate('blocked_humans');
export const blocked_goodbots = new Rate('blocked_goodbots');
export const blocked_trashbots = new Rate('blocked_trashbots');
export const blocked_stealth = new Rate('blocked_stealth');
```

In each scenario function:

```js
export function humanFlow() {
  const res = http.get(`${BASE_URL}/`, { headers: humanHeaders });
  const isBlocked = res.status === 403 || res.headers['X-BotDetection-Action'] === 'Block';
  blocked_humans.add(isBlocked);
  // ...
}
```

…and similarly for goodbots / trashbots / stealth.

---

## 6. k6 Thresholds (Functional Criteria)

Add thresholds at the top:

```js
export const options = {
  // ... scenarios ...
  thresholds: {
    // Humans: low false positive
    'blocked_humans': ['rate<=0.005'],        // ≤0.5%

    // Good bots: mostly allowed / throttled, not hard-blocked
    'blocked_goodbots': ['rate<=0.01'],       // ≤1%

    // Trash bots: very aggressively blocked
    'blocked_trashbots': [
      'rate>=0.95',                           // general load phase
    ],

    // Stealth: should be learned + choked off over time (esp. in soak)
    'blocked_stealth': [
      'rate>=0.7',                            // mid/late soak
    ],
  },
};
```

For **time-bounded thresholds** in soak, you can either:

* Run separate stages and separate tests (short vs long soak); or
* Use tags or multiple runs and inspect through Prometheus/OTEL instead of a single k6 assertion.

k6 itself doesn’t do “rate>=0.95 after 30s” directly, but you can:

* Run a **short warm-up test** where you **ignore** first N seconds via stages and only collect metrics in later
  stages (or just visually ignore warm-up for thresholds).
* Or split it:

    * `k6 run warmup-trashbots.js`
    * `k6 run steady-trashbots.js` (thresholds apply here).

---

## 7. Soak Test Specification

### 7.1 Mixed Soak (Primary)

**Goal:** Simulate a realistic mix of traffic for 1–2 hours and verify:

* Detection & reputation stay sane.
* Block/allow rates stabilise and don’t drift into nonsense.
* No memory / performance spiral.

**Config**

* Duration: `1h` (start) → `2–4h` (later).
* Scenarios:

    * Humans: 50–70% traffic.
    * Good bots: 5–10%.
    * Trash bots: 10–20%.
    * Stealth: 10–15%.

Rough example:

```js
export const options = {
  scenarios: {
    humans: {
      executor: 'ramping-vus',
      startVUs: 5,
      stages: [
        { duration: '10m', target: 30 },
        { duration: '40m', target: 30 },
        { duration: '10m', target: 0 },
      ],
      exec: 'humanFlow',
    },
    goodBots: {
      executor: 'constant-vus',
      vus: 5,
      duration: '1h',
      exec: 'goodBotFlow',
    },
    trashBots: {
      executor: 'constant-arrival-rate',
      rate: 50,
      timeUnit: '1s',
      duration: '1h',
      preAllocatedVUs: 30,
      exec: 'trashBotFlow',
    },
    stealthScrapers: {
      executor: 'per-vu-iterations',
      vus: 20,
      iterations: 300, // stretched over the hour with sleeps
      exec: 'stealthFlow',
    },
  },
  thresholds: {
    'blocked_humans': ['rate<=0.005'],
    'blocked_goodbots': ['rate<=0.01'],
    'blocked_trashbots': ['rate>=0.95'],
    'blocked_stealth': ['rate>=0.7'],
  },
};
```

**Additional Soak Metrics (non-functional)**

* `http_req_duration{scenario:humans}` p95/p99 (ensure bot detection isn’t blowing latency).
* Memory / CPU of the SUT (via OTEL / Prometheus).
* Count of **reputation entries** over time:

    * Should grow then stabilise; not unbounded.

### 7.2 Targeted Soak: Reputation & Forgetting

**Goal:** Validate that reputation & decay behave as intended.

**Phases**

1. **Attack phase** (30–60 min):

    * Hammer with trash bots & stealth from a set of IP ranges & UAs.
    * Check that those patterns become ConfirmedBad / heavily blocked.
2. **Quiet phase** (another 30–60 min):

    * Reduce/stop that traffic, keep normal human flow.
    * Observe:

        * Reputation scores slowly drifting back toward neutral (over your configured τ).
        * No new weird blocking of humans.
3. Optional: **Re-attack**:

    * Reintroduce bots and confirm the system “remembers enough” to react quickly if support hasn’t decayed fully.

Most of this you’ll inspect via logs / OTEL metrics, but k6 still provides the controlled traffic.

---

## 8. Test Cases Summary

1. **T01 – Human Browsing (Short)**

    * Validate <0.5% blocks, Low risk, low latency.

2. **T02 – Good Bot Crawl**

    * Validate almost zero hard blocks, risk high but mapped to Allow/Throttle.

3. **T03 – Trash Bot Burst**

    * Short load; confirm block rate ramping to ≥95% quickly.

4. **T04 – Stealth Scraper Behavioural Detection**

    * 15–30 min; confirm gradually rising block rate ≥70%.

5. **T05 – Path-Escalated Protection**

    * Attack `/login`, `/checkout`, `/api/private/**`; verify ≥99% block on obvious attacks, low FP for legit users.

6. **T06 – Mixed Soak (1–2h)**

    * All profiles mixed; validate threshold criteria & stability.

7. **T07 – Reputation & Forgetting Soak**

    * Attack → quiet → optional re-attack; validate reputation behaviour with time decay (mainly via telemetry).

---

If you like, next step I can turn this into a **real k6 repo layout** (with `useragents.js`, `scenarios.js`,
`thresholds.js`) so you can just drop it into your playground and start abusing your poor middleware properly.
